{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "etf_codelist = pd.read_csv(\"tw_maincode_etf__2025.csv\")\n",
    "list_ = etf_codelist['code'].values\n",
    "_price = pd.read_parquet(\"tw_price.parquet\")\n",
    "op_df = _price.pivot_table(index='da', columns=\"code\", values='op')\n",
    "hi_df = _price.pivot_table(index='da', columns=\"code\", values='hi')\n",
    "lo_df = _price.pivot_table(index='da', columns=\"code\", values='lo')\n",
    "cl_df = _price.pivot_table(index='da', columns=\"code\", values='cl')\n",
    "vol_df = _price.pivot_table(index='da', columns=\"code\", values='vol')\n",
    "to_df = _price.pivot_table(index='da', columns=\"code\", values='turnover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_da = '2020-01-01'\n",
    "end_da = \"2020-04-01\"\n",
    "to_df = to_df[to_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "op_df = op_df[op_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "cl_df = cl_df[cl_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "hi_df = hi_df[hi_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "lo_df = lo_df[lo_df.columns.intersection(list_)].loc[start_da:end_da, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_lo_log = np.log(hi_df / lo_df)\n",
    "next_day_log = np.log(cl_df / op_df).shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 187, 280, 186)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = hi_lo_log.std()\n",
    "profit = hi_lo_log.sum(axis=0)\n",
    "len(std), len(std.dropna()), len(profit), len(profit[profit != 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00643K TT Equity\n"
     ]
    }
   ],
   "source": [
    "# R反L槓桿, K, U指數股票型, B+C債\n",
    "list_exclude = []\n",
    "list_include = []\n",
    "std_test = std.dropna()\n",
    "profit_test = profit[profit != 0]\n",
    "\n",
    "# test for the first time\n",
    "for i in std_test.index:\n",
    "    if i not in profit_test.index: print(i); list_exclude.append(i); continue;\n",
    "    if \"L\" in i: list_exclude.append(i)\n",
    "    elif \"B\" in i: list_exclude.append(i)\n",
    "    elif \"C\" in i: list_exclude.append(i)\n",
    "    elif \"R\" in i: list_exclude.append(i)\n",
    "    else: list_include.append(i)\n",
    "\n",
    "std_test = std_test[std_test.index.intersection(list_include)]\n",
    "profit_test = profit_test[profit_test.index.intersection(list_include)]\n",
    "\n",
    "# test again\n",
    "for i in std_test.index:\n",
    "    if i not in profit_test.index: print(i);\n",
    "\n",
    "len(std_test), len(profit_test)\n",
    "arr_test = np.column_stack((std_test, profit_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  10 of 10 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 使用KNN进行分群\u001b[39;00m\n\u001b[1;32m     41\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmahalanobis\u001b[39m\u001b[38;5;124m'\u001b[39m, metric_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m: inv_cov})\n\u001b[0;32m---> 42\u001b[0m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmahalanobis_distances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 分群预测\u001b[39;00m\n\u001b[1;32m     45\u001b[0m clusters \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(features_scaled)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:238\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neighbors/_base.py:499\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# Using `dtype=np.intp` is necessary since `np.bincount`\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (called in _classification.py) fails when dealing\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# with a float64 array on 32bit systems.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m ]:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.covariance import MinCovDet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 下载股票数据\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'AMD', 'BA', 'NFLX']\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2025-01-01'\n",
    "data = yf.download(stocks, start=start_date, end=end_date)['Adj Close']\n",
    "\n",
    "# 计算每日收益率和波动度（标准差）\n",
    "returns = data.pct_change().dropna()  # 计算每日收益率\n",
    "volatility = returns.std()  # 计算每日收益率的标准差作为波动度\n",
    "\n",
    "# 计算收益的均值\n",
    "mean_returns = returns.mean()\n",
    "\n",
    "# 将波动度和收益合并成特征\n",
    "features = pd.DataFrame({\n",
    "    'Return': mean_returns,\n",
    "    'Volatility': volatility\n",
    "})\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 计算Mahalanobis距离\n",
    "cov = np.cov(features_scaled.T)\n",
    "inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "# 使用MinCovDet方法来得到Mahalanobis距离的估计\n",
    "mcd = MinCovDet().fit(features_scaled)\n",
    "mahalanobis_distances = mcd.mahalanobis(features_scaled)\n",
    "\n",
    "# 使用KNN进行分群\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='mahalanobis', metric_params={'V': inv_cov})\n",
    "knn.fit(features_scaled, mahalanobis_distances)\n",
    "\n",
    "# 分群预测\n",
    "clusters = knn.predict(features_scaled)\n",
    "\n",
    "# 可视化结果\n",
    "plt.scatter(features_scaled[:, 0], features_scaled[:, 1], c=clusters, cmap='viridis')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Volatility')\n",
    "plt.title('Stock Clusters using KNN + Mahalanobis Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"2025_v1_tickers_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>25.02</td>\n",
       "      <td>25.04</td>\n",
       "      <td>24.96</td>\n",
       "      <td>24.96</td>\n",
       "      <td>59</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close  volume symbol\n",
       "0 2023-12-29  25.02  25.04  24.96  24.96      59    AAA"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_df = df.pivot_table(index='date', columns=\"symbol\", values='open')\n",
    "hi_df = df.pivot_table(index='date', columns=\"symbol\", values='high')\n",
    "lo_df = df.pivot_table(index='date', columns=\"symbol\", values='low')\n",
    "cl_df = df.pivot_table(index='date', columns=\"symbol\", values='close')\n",
    "vol_df = df.pivot_table(index='date', columns=\"symbol\", values='volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
