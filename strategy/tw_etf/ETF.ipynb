{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "etf_codelist = pd.read_csv(\"../../database/tw_maincode_etf__2025.csv\")\n",
    "list_ = etf_codelist['code'].values\n",
    "_price = pd.read_parquet(\"../../database/tw_price.parquet\")\n",
    "op_df = _price.pivot_table(index='da', columns=\"code\", values='op')\n",
    "hi_df = _price.pivot_table(index='da', columns=\"code\", values='hi')\n",
    "lo_df = _price.pivot_table(index='da', columns=\"code\", values='lo')\n",
    "cl_df = _price.pivot_table(index='da', columns=\"code\", values='cl')\n",
    "vol_df = _price.pivot_table(index='da', columns=\"code\", values='vol')\n",
    "to_df = _price.pivot_table(index='da', columns=\"code\", values='turnover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 187, 280, 186)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_da = '2020-01-01'\n",
    "end_da = \"2020-04-01\"\n",
    "to_df = to_df[to_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "op_df = op_df[op_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "cl_df = cl_df[cl_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "hi_df = hi_df[hi_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "lo_df = lo_df[lo_df.columns.intersection(list_)].loc[start_da:end_da, :]\n",
    "\n",
    "hi_lo_log = np.log(hi_df / lo_df)\n",
    "next_day_log = np.log(cl_df / op_df).shift(-1)\n",
    "\n",
    "std = hi_lo_log.std()\n",
    "profit = hi_lo_log.sum(axis=0)\n",
    "len(std), len(std.dropna()), len(profit), len(profit[profit != 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00643K TT Equity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68, 68)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R反L槓桿, K, U指數股票型, B+C債 cleaning\n",
    "list_exclude = []; list_include = []\n",
    "std_test = std.dropna(); profit_test = profit[profit != 0]\n",
    "\n",
    "# test for the first time\n",
    "for i in std_test.index:\n",
    "    if i not in profit_test.index: print(i); list_exclude.append(i); continue;\n",
    "    if \"L\" in i: list_exclude.append(i)\n",
    "    elif \"B\" in i: list_exclude.append(i)\n",
    "    elif \"C\" in i: list_exclude.append(i)\n",
    "    elif \"R\" in i: list_exclude.append(i)\n",
    "    else: list_include.append(i)\n",
    "\n",
    "std_test = std_test[std_test.index.intersection(list_include)]\n",
    "profit_test = profit_test[profit_test.index.intersection(list_include)]\n",
    "\n",
    "# test again\n",
    "for i in std_test.index:\n",
    "    if i not in profit_test.index: print(i);\n",
    "\n",
    "arr_test = np.column_stack((std_test, profit_test))\n",
    "len(std_test), len(profit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 59, 68)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 2\n",
    "centroids = arr_test[np.random.choice(len(arr_test), K, replace=False)]\n",
    "clusters = [[] for _ in range(K)]\n",
    "\n",
    "\n",
    "for point in arr_test:\n",
    "    distances = []\n",
    "    for i in range(len(centroids)):\n",
    "        stacks = np.vstack([centroids[i], point]).T\n",
    "        cov = np.cov(stacks)\n",
    "        \n",
    "        regularized_cov = cov + np.eye(cov.shape[0]) * 1e-5  # 添加小數值\n",
    "        inv_cov = np.linalg.inv(regularized_cov)\n",
    "\n",
    "        \n",
    "        V = np.linalg.inv(inv_cov)\n",
    "        diff = (centroids[i] - point)\n",
    "        val = diff.T @ V @ diff\n",
    "        distances.append(val)\n",
    "    cluster_index = np.argmin(distances)\n",
    "    clusters[cluster_index].append(point)\n",
    "len(clusters[0]), len(clusters[1]), len(arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, tol=1e-5):\n",
    "        self.tol = tol\n",
    "        \n",
    "    def clustering(self, data):\n",
    "        pass\n",
    "    \n",
    "    def convergence_test(self, new_centroids, centroids) -> bool:\n",
    "        if len(new_centroids) != len(centroids):\n",
    "            return False\n",
    "        return np.all(np.linalg.norm(new_centroids - centroids, axis=1) <= self.tol)\n",
    "    \n",
    "    def convergence_test_raw(self, new_centroids, centroids):\n",
    "        if len(new_centroids) != len(centroids):\n",
    "            return False\n",
    "        \n",
    "        for i in range(len(new_centroids)):\n",
    "            if np.any(abs(new_centroids[i] - centroids[i])) > self.tol:  # 若任一元素超過誤差範圍\n",
    "                return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cl_df = cl_df[['0050 TT Equity']].pct_change()\n",
    "pct_cl_df['tom'] = pct_cl_df.shift(1)\n",
    "pct_cl_df = pct_cl_df.iloc[2:]\n",
    "\n",
    "data = np.array(pct_cl_df)\n",
    "def distances_k_means(point_diff, method='eucldiean'):\n",
    "    if method == 'eucldiean':\n",
    "        return np.sqrt(\n",
    "            np.sum(\n",
    "                (point_diff) ** 2)\n",
    "        )\n",
    "    elif method == 'norm':\n",
    "        return np.linalg.norm(point_diff)\n",
    "    else: return None;\n",
    "    \n",
    "def mahalanobis_distance(point_diff, mean_vector, covariance_vector):\n",
    "    return (point_diff - mean_vector) @ np.linalg.inv(covariance_vector) @ np.linalg.matrix_transpose(point_diff - mean_vector)\n",
    "\n",
    "def convergence_test(a, b, tol=1e-5):\n",
    "    if len(a) != len(b):\n",
    "        return False\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        print(a[i], b[i])\n",
    "        if np.any(abs(a[i] - b[i])) > tol:  # 若任一元素超過誤差範圍\n",
    "            return False\n",
    "    \n",
    "    return True  # 所有元素都接近\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "def compute_sse(clusters, centroids):\n",
    "    \"\"\"計算 SSE (Sum of Squared Errors)\"\"\"\n",
    "    sse = 0\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for point in cluster:\n",
    "            sse += np.linalg.norm(point - centroids[i])**2\n",
    "    return sse\n",
    "\n",
    "def convergence_test(new_centroids, centroids, tol=1e-5):\n",
    "    return np.all(np.linalg.norm(new_centroids - centroids, axis=1) <= tol)\n",
    "\n",
    "K = 3\n",
    "num_iterations = 100\n",
    "plot_interval = 10  # Change this to control how often the plot is generated\n",
    "\n",
    "centroids = data[np.random.choice(len(data), K, replace=False)]\n",
    "\n",
    "# List to store centroids for each iteration\n",
    "centroids_history = []\n",
    "sse_list = []\n",
    "# Calculate how many plots will be shown based on plot_interval\n",
    "plots_to_show = math.ceil(num_iterations / plot_interval)\n",
    "\n",
    "# Dynamically calculate the number of rows and columns based on plots_to_show\n",
    "cols = math.ceil(math.sqrt(plots_to_show))  \n",
    "rows = math.ceil(plots_to_show / cols)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))  \n",
    "axes = axes.flatten()  # Flatten the axes to make it easy to index\n",
    "\n",
    "plot_counter = 0  # Counter to track how many plots we've made\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    clusters = [[] for _ in range(K)]\n",
    "\n",
    "    for point in data:\n",
    "        distances = [distances_k_means(point - centroid) for centroid in centroids]\n",
    "        cluster_index = np.argmin(distances)\n",
    "        clusters[cluster_index].append(point)\n",
    "\n",
    "    new_centroids = np.array([np.mean(cluster, axis=0) if cluster else centroids[i] \n",
    "                              for i, cluster in enumerate(clusters)])\n",
    "\n",
    "    # Save the current centroids to centroids_history\n",
    "    centroids_history.append(new_centroids)\n",
    "\n",
    "    # Only plot every 'plot_interval' iterations\n",
    "    if (iteration + 1) % plot_interval == 0:\n",
    "        ax = axes[plot_counter]  # Get the next available axis to plot\n",
    "        plot_counter += 1  # Increment the plot counter\n",
    "        ax.set_title(f\"Iteration {iteration + 1}\")\n",
    "\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            cluster_points = np.array(cluster)\n",
    "            if len(cluster_points) > 0:\n",
    "                ax.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {i}')\n",
    "        ax.scatter(new_centroids[:, 0], new_centroids[:, 1], c='black', marker='X', s=100, label='New Centroids')\n",
    "        ax.legend()\n",
    "\n",
    "    if convergence_test(new_centroids, centroids):\n",
    "        print(f\"K-Means 收斂於 Iteration {iteration+1}\")\n",
    "        break\n",
    "    centroids = new_centroids  \n",
    "    sse = compute_sse(clusters=clusters, centroids=centroids)\n",
    "    sse_list.append(sse)\n",
    "# Remove any remaining unused axes (in case plots_to_show is smaller than the total axes)\n",
    "for i in range(plot_counter, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "fig.tight_layout()  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
